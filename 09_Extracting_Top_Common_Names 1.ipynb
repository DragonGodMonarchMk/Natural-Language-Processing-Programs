{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e510a2ff-4255-44d2-8114-a83cd3206c20",
   "metadata": {},
   "source": [
    "###  Extracting Top Common Words - Extract the top 10 most common words in the text excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192143ae-c35d-403b-847d-71b90cf87bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4baf7e-e919-4b3d-8b39-f543154bc882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1531f3d-1955-4cf7-a0b9-b4c1f80b40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(text, top_n=10):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text.lower())  # Convert to lowercase for case-insensitive counting\n",
    "\n",
    "    # Filter out stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(filtered_words)\n",
    "\n",
    "    # Get the top N words\n",
    "    top_words = word_freq.most_common(top_n)\n",
    "\n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19249cff-05e1-4578-8df3-21ac987e74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common Words (excluding stopwords):\n",
      "text: 2\n",
      "input: 1\n",
      "goes: 1\n",
      "replace: 1\n",
      "actual: 1\n",
      "want: 1\n",
      "analyze: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "text_to_analyze = \"Your input text goes here. Replace it with the actual text you want to analyze.\"\n",
    "\n",
    "top_words_result = get_top_words(text_to_analyze, top_n=10)\n",
    "\n",
    "print(\"Top 10 Most Common Words (excluding stopwords):\")\n",
    "for word, frequency in top_words_result:\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e93c8-51f2-4a53-969e-a118774de9dc",
   "metadata": {},
   "source": [
    "#### ...Implement the same code for a text document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cb87cf-2a44-4c76-9244-2daf221b522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Common Words (excluding stopwords):\n",
      "hypocrites: 3\n",
      "good: 2\n",
      "morning: 2\n",
      "ye: 1\n",
      "thou: 1\n",
      "say: 1\n",
      "patients: 1\n",
      "worse: 1\n",
      "cruel: 1\n",
      "phony: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_words_from_file(file_path, top_n=10):\n",
    "    # Download required nltk resources if not already downloaded\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    # Read the content from the text document\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text.lower())  # Convert to lowercase for case-insensitive counting\n",
    "\n",
    "    # Filter out stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(filtered_words)\n",
    "\n",
    "    # Get the top N words\n",
    "    top_words = word_freq.most_common(top_n)\n",
    "\n",
    "    return top_words\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'demo.txt'\n",
    "top_words_result = get_top_words_from_file(file_path, top_n=10)\n",
    "\n",
    "print(\"Top 10 Most Common Words (excluding stopwords):\")\n",
    "for word, frequency in top_words_result:\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
