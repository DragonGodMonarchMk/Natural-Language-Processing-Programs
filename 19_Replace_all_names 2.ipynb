{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwfR_8yLKKEx"
   },
   "source": [
    "# Replacing all the nouns by UNKNWON using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYa5EcMnUAqn",
    "outputId": "66bcf3f1-7c92-4513-c594-7efbfd579f25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk #module\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker') #pre-trained model (Maximum Entropy (MaxEnt) classifier)\n",
    "nltk.download('words') #spell checking and wordsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MuqrCQ_aRkgi"
   },
   "outputs": [],
   "source": [
    "def replace_names(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Perform Part-of-Speech tagging\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    # Perform Named Entity Recognition (NER)\n",
    "    named_entities = ne_chunk(pos_tags)\n",
    "\n",
    "    # Replace names with UNKNOWN\n",
    "    replaced_text = []\n",
    "    for entity in named_entities:\n",
    "        if isinstance(entity, tuple):\n",
    "            replaced_text.append(entity[0])\n",
    "        else:\n",
    "            if entity.label() == 'PERSON':\n",
    "                replaced_text.append('UNKNOWN')\n",
    "            else:\n",
    "                replaced_text.extend([word[0] for word in entity])\n",
    "\n",
    "    # Combine words into a single string\n",
    "    replaced_text = ' '.join(replaced_text)\n",
    "\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruh5KFgES6iF",
    "outputId": "5976bb97-6af6-4eea-c3c4-95975e3cedb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN , a renowned scientist , won the Nobel Prize in Physics . He was born in New York City . The CEO of the company , UNKNOWN , announced record-breaking profits for the quarter . UNKNOWN , the famous actress , starred in the new blockbuster movie .\n"
     ]
    }
   ],
   "source": [
    "# Sample news article\n",
    "news_article = \"\"\"\n",
    "John Sam, a renowned scientist, won the Nobel Prize in Physics. He was born in New York City.\n",
    "The CEO of the company, Jane Doe, announced record-breaking profits for the quarter.\n",
    "Emma Watson, the famous actress, starred in the new blockbuster movie.\n",
    "\"\"\"\n",
    "\n",
    "# Replace names in the news article\n",
    "replaced_article = replace_names(news_article)\n",
    "print(replaced_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAY4C2SMTNPU"
   },
   "source": [
    "# Replacing all the nouns by UNKNWON using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0lYpFEF2TLZ-"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "75mEeVUAU4Q-"
   },
   "outputs": [],
   "source": [
    "def replace_names(text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Initialize variables\n",
    "    replaced_text = []\n",
    "    is_replacing = False\n",
    "    replaced_names = set()\n",
    "    current_name = []\n",
    "\n",
    "    # Iterate through tokens\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            if not is_replacing:\n",
    "                is_replacing = True\n",
    "            current_name.append(token.text)\n",
    "        else:\n",
    "            if is_replacing:\n",
    "                # Combine first name and last name\n",
    "                combined_name = \" \".join(current_name)\n",
    "                if combined_name not in replaced_names:\n",
    "                    replaced_text.append(\"UNKNOWN\")\n",
    "                    replaced_names.add(combined_name)\n",
    "                else:\n",
    "                    replaced_text.append(\" \".join(current_name))\n",
    "                current_name = []\n",
    "                is_replacing = False\n",
    "            replaced_text.append(token.text)\n",
    "\n",
    "    # Combine words into a single string\n",
    "    replaced_text = \" \".join(replaced_text)\n",
    "\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bwI6U6RVAvI",
    "outputId": "a8ec7203-320c-46fc-d880-41fe52e1b40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " UNKNOWN , a renowned scientist , won the Nobel Prize in Physics . He was born in New York City . \n",
      "\n",
      " The CEO of the company , UNKNOWN , announced record - breaking profits for the quarter . \n",
      "\n",
      " UNKNOWN , the famous actress , starred in the new blockbuster movie . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample news article\n",
    "news_article = \"\"\"\n",
    "John Smith, a renowned scientist, won the Nobel Prize in Physics. He was born in New York City.\n",
    "\n",
    "The CEO of the company, Jane Doe, announced record-breaking profits for the quarter.\n",
    "\n",
    "Emma Watson, the famous actress, starred in the new blockbuster movie.\n",
    "\"\"\"\n",
    "\n",
    "# Replace names in the news article\n",
    "replaced_article = replace_names(news_article)\n",
    "print(replaced_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDHFnMqhVCNI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
